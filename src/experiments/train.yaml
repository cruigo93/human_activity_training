EXPERIMENT_NAME: "baseline"

DATA:
  IMAGE_DIR: /home/zhuldyzzhan/research/human_activities/data/train
  FILE: "/home/zhuldyzzhan/research/human_activities/data/Training_set.csv"
  BATCH_SIZE: 16
  VAL_SIZE: 0.3

OPTIMIZER:
  PY: torch.optim
  CLASS: AdamW
  ARGS:
    lr: 0.0001
    weight_decay: 0.000005

MODEL:
  PY: models
  CLASS: EffNet
  ARGS:
    arch_name: "efficientnet-b0"
    num_classes: 15

GRADIENT_ACCUMULATION_STEPS: 4
GRADIENT_CLIPPING: 0.1

SCHEDULER:
  PY: torch.optim.lr_scheduler
  CLASS: CosineAnnealingWarmRestarts
  ARGS:
    T_0: 1
    T_mult: 2

CRITERION:
  PY: torch.nn
  CLASS: CrossEntropyLoss

AUGMENTATION:
  PY: transforms
  TRAIN: get_train_transforms
  VAL: get_train_transforms

EARLY_STOPPING:
  ARGS:
    monitor: "val_score"
    min_delta: 0.00
    patience: 10
    verbose: True
    mode: "max"

CHECKPOINT:
  ARGS:
    save_top_k: 3
    verbose: True
    monitor: "val_score"
    mode: "max"

EPOCHS: 100
GPUS: [1]
